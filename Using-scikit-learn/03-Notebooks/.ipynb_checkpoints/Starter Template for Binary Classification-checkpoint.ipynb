{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Stylianos Kampakis & Shreesha Jagadeesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to give a general overview for creating a binary classifier on an imbalanced datasets using familiar sklearn-based ML algorithms. \n",
    "The dataset is given here https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "Also the notebook contains useful functions that will be used to explore the kind of datasets used in this LiveProjects. Students are encouraged to familiarize themselves with the coding style as well as the concepts covered in this notebook becasue these will be referred to throughout the course.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a> <br>\n",
    "## Table of  Contents\n",
    "1. [Introduction](#1)\n",
    "\n",
    "1. [Initialization](#2)\n",
    "    1. [Load packages](#21)\n",
    "    1. [Define Metadata](#22)\n",
    "    \n",
    "1. [Load Data](#3)\n",
    "\n",
    "1. [Data Insights](#4)\n",
    "    1. [Data Structure](#41)\n",
    "    1. [Summary Stats](#42)\n",
    "    1. [Unique Value Checking](#43)\n",
    "    1. [Identifying 'Bad Columns'](#44)\n",
    "\n",
    "1. [Data Cleansing](#5)\n",
    "    1. [Data Reduction](#51)\n",
    "        1. [Dropping Bad Columns](#511)\n",
    "        1. [Null Value Removal](#512)\n",
    "\n",
    "1. [Modelling Workflow](#6)\n",
    "    1. [Data Prep](#61)\n",
    "        1. [Feature Target Split](#611)\n",
    "        1. [Train-Test Split](#612)\n",
    "        1. [Normalizing Numerical Variables](#613)\n",
    "    1. [Estimate of Baseline Accuracy - Class Distributions](#62)\n",
    "    1. [Predictive Modelling](#63)\n",
    "        1. [Modelling with Random Forest](#631)\n",
    "        1. [Model Comparison](#632)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1'>Introduction</a>  \n",
    "\n",
    "Assume you work for a financial institution that issues credit cards to customers. Once the credit card is in the hands of the customers, it is important that the customer is alerted and the card possibly blocked upon the detection of fraudulent transactions. In this dataset, we deal with anonymized data from a Kaggle competition containing credit card transactions.\n",
    "\n",
    "\"The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\"\n",
    "\n",
    "We will be loading the data and applying some basic checks to see if the data needs to cleaned. Subsequently, we will use a RandomForestClassifier to fit on the train and predict on the test data. A custom function is used to evaluate the model performance \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2'>Initialization</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='21'>Load Packages</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the minimum number of packages to get started and add more as we go along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# This is to suppress any deprecation warnings \n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='22'>Define Metadata</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the target class column here instead of manually typing it out everywhere\n",
    "target_class_name = 'Class'\n",
    "\n",
    "# Fill in the names of what you want to call the 0 and 1 class\n",
    "labels = ['Not Fraud', 'Fraud']\n",
    "\n",
    "input_file_name = 'creditcard.csv'\n",
    "raw_data_folder = '../01-Data/Raw/'\n",
    "\n",
    "# Enter the date in which this notebook is run\n",
    "export_date = '20240612'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3'>Load Data</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/creditcard.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the data from the raw sub-folder within the data folder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Take a random sample to see how the data looks like\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/AnomDetn/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AnomDetn/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AnomDetn/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/AnomDetn/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AnomDetn/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/AnomDetn/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/raw/creditcard.csv'"
     ]
    }
   ],
   "source": [
    "# Read the data from the raw sub-folder within the data folder\n",
    "df = pd.read_csv(raw_data_folder + input_file_name)\n",
    "\n",
    "# Take a random sample to see how the data looks like\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the head & tail to make sure there is nothing going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "284804  172788.0  1.919565 -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  172788.0 -0.240440  0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  172792.0 -0.533413 -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "284804 -0.296827  0.708417  0.432454  ...  0.232045  0.578229 -0.037501   \n",
       "284805 -0.686180  0.679145  0.392087  ...  0.265245  0.800049 -0.163298   \n",
       "284806  1.577006 -0.414650  0.486180  ...  0.261057  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88      0  \n",
       "284805  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00      0  \n",
       "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No trouble with loading the data. Both the head and tail are clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=4 > Data Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='41'>Data Structure</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Lets see the data structure\n",
    "df.info()\n",
    "# This will give you how many rows & columns are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the columns have null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='42'>Summary Stats</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.describe()\n",
    "# check out each column's summary statistics\n",
    "# Note that only the numerical columns will be described\n",
    "# Also you will want to exclude the discrete columns whose summary stats will give non-sensical values like 'customer_id' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='43'>Unique Value Checking</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 124592\n",
      "V1 275663\n",
      "V2 275663\n",
      "V3 275663\n",
      "V4 275663\n",
      "V5 275663\n",
      "V6 275663\n",
      "V7 275663\n",
      "V8 275663\n",
      "V9 275663\n",
      "V10 275663\n",
      "V11 275663\n",
      "V12 275663\n",
      "V13 275663\n",
      "V14 275663\n",
      "V15 275663\n",
      "V16 275663\n",
      "V17 275663\n",
      "V18 275663\n",
      "V19 275663\n",
      "V20 275663\n",
      "V21 275663\n",
      "V22 275663\n",
      "V23 275663\n",
      "V24 275663\n",
      "V25 275663\n",
      "V26 275663\n",
      "V27 275663\n",
      "V28 275663\n",
      "Amount 32767\n",
      "Class 2\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(column, len(df[column].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='44'>Identifying Bad Columns</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_columns_function(dataframe):\n",
    "    '''\n",
    "    Args: dataframe for which there maybe columns of concern that need to be fixed or deleted\n",
    "    \n",
    "    Logic: Find the columns that have \n",
    "    Null values\n",
    "    blanks in the strings\n",
    "    quasi constant/constant values defined by less than 1% variance\n",
    "    \n",
    "    Returns: 4 lists containing those features that have nulls, blanks, constant values throughout for numerical and categorical\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ###### Finding Null Values\n",
    "    null_col_list = dataframe.columns[dataframe.isna().any()].tolist()\n",
    "    \n",
    "    print('Identified {} features with atleast one null'.format(\n",
    "        len(null_col_list)))\n",
    "\n",
    "    ###### Finding Blank Spaces in the object column\n",
    "    # Non-obvious nulls such as blanks: The line items where there are spaces \n",
    "    blank_space_col_list = []\n",
    "    object_columns = dataframe.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in object_columns:\n",
    "        if sum(dataframe[col]==' '):\n",
    "            blank_space_col_list.append(col)\n",
    "\n",
    "    print('Identified {} features with atleast one blank space'.format(\n",
    "        len(blank_space_col_list)))\n",
    "    \n",
    "    ####### Finding Quasi Constant/Constant Value in numerical columns\n",
    "    # Lets remove the variables that have more than 99% of their values as the same \n",
    "    # ie their standard deviation is less than 1 %\n",
    "    \n",
    "    numeric_df = dataframe._get_numeric_data()\n",
    "    constant_numeric_col_list = [col for col in numeric_df.columns if numeric_df[col].std()<0.01]\n",
    "\n",
    "    print('Identified {} numeric features that have quasi-constant values'.format(\n",
    "        len(constant_numeric_col_list)))\n",
    "    \n",
    "    # We use a separate logic for the non-numerical variables because if you have closely varying float values\n",
    "    # then the below code snippet wont pick it up\n",
    "    \n",
    "    ###### Finding Quasi Constant/Constant non_numeric value\n",
    "    constant_non_numeric_col_list = []\n",
    "    \n",
    "    # Find the columns that are not in numeric_df\n",
    "    non_numeric_col_set = set(dataframe.columns) - set(numeric_df.columns)   \n",
    "\n",
    "    for col in non_numeric_col_set:\n",
    "        categorical_mode_value = (dataframe[col].mode().values)[0]\n",
    "        fractional_presence = sum(dataframe[col]==categorical_mode_value)/len(dataframe) \n",
    "    \n",
    "        if fractional_presence > 0.99:\n",
    "            constant_non_numeric_col_list.append(col)\n",
    "            \n",
    "    print('Identified {} non-numeric features that have quasi-constant values'.format(\n",
    "        len(constant_non_numeric_col_list)))\n",
    "    \n",
    "    return null_col_list, blank_space_col_list, constant_numeric_col_list, constant_non_numeric_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 features with atleast one null\n",
      "Identified 0 features with atleast one blank space\n",
      "Identified 0 numeric features that have quasi-constant values\n",
      "Identified 0 non-numeric features that have quasi-constant values\n"
     ]
    }
   ],
   "source": [
    "# use the above custom function to figure out the if there are any columns we need to be concerned about\n",
    "null_col_list, blank_space_col_list, constant_numeric_col_list, \\\n",
    "constant_non_numeric_col_list = find_bad_columns_function(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be any obvious columns that need attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5'>Data Cleansing</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='51'>Data Reduction</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='511'>Dropping Bad Columns</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping irrelevant features and duplicated columns,\n",
      "31 number of columns were present\n",
      "After dropping the above, \n",
      "31 number of columns are present\n"
     ]
    }
   ],
   "source": [
    "# In this dataset, we dont have anything of concern that need deletion but \n",
    "# But if they do show up, you should go ahead and delete them to reduce overfitting\n",
    "\n",
    "print('Before dropping irrelevant features and duplicated columns,')\n",
    "print('{} number of columns were present'.format(len(df.columns)))\n",
    "\n",
    "for drop_column_list in [constant_numeric_col_list, constant_non_numeric_col_list]:\n",
    "    df.drop(drop_column_list, axis=1, inplace=True)\n",
    "\n",
    "print('After dropping the above, ')\n",
    "print('{} number of columns are present'.format(len(df.columns)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='512'>Null Value Removal</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = 6 > Modelling Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 61 > Data Prep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='611'>Feature - Target Split</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(target_class_name, axis=1)\n",
    "y = df[target_class_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='612'>Train Test Split</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Note optionally convert the pandas dataframe into a numpy array using to_numpy if you have a big data\n",
    "# and want to model faster. Otherwise it doesnt matter which data structure you use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = 612 > Normalizing numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have numerical features, can we feed it directly into our models like Random Forest? Yes even without scaling or normalizing. Scaling has the effect of squeezing all data range into a tight range but is not required for non-distance based models\n",
    "\n",
    "https://stats.stackexchange.com/questions/244507/what-algorithms-need-feature-scaling-beside-from-svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='62'>Estimate of baseline accuracy - Class Distributions </a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Negative class is 99.827 %\n",
      "Percentage of Positive class is 0.173 %\n"
     ]
    }
   ],
   "source": [
    "# Figure out the class distribution percentage and round it to 3 decimal places\n",
    "\n",
    "print('Percentage of Negative class is {} %'.format(\n",
    "    round(df[target_class_name].value_counts()[0]/len(df) * 100,3)))\n",
    "\n",
    "print('Percentage of Positive class is {} %'.format(\n",
    "    round(df[target_class_name].value_counts()[1]/len(df) * 100,3)))\n",
    "\n",
    "# A dumb model that predicts everything as being 0, will generate a baseline accuracy of 99.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "pd.value_counts(df[target_class_name]).plot.bar()\n",
    "plt.title('Histogram of class distributions')\n",
    "plt.xlabel(labels[1])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Frequency')\n",
    "df[target_class_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy to beat is 99.8%\n",
    "\n",
    "What about the other metrics like Precision, Recall and F1 score? They would all be 0% for the positive class for a non-predictive 'classifier' that predicts every  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='63'>Predictive Modelling</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='631'>Modelling with Random Forest</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, average_precision_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse the same function from the starter template\n",
    "def custom_classification_metrics_function(X_test, y_test, labels, classifier):\n",
    "    '''\n",
    "    Args: The features and the target column; the labels are the categories, sklearn classifier object\n",
    "    Calculates Classification metrics of interest\n",
    "    Returns: A dictionary containing the classification metrics\n",
    "    '''\n",
    "\n",
    "    # Generate the predictions on the test data which forms the basis of the evaluation metrics\n",
    "    test_pred = classifier.predict(X_test)\n",
    "\n",
    "    ### Classification report\n",
    "    print(classification_report(y_test, test_pred, target_names=labels))\n",
    "    \n",
    "    # Only store the 2nd column which corresponds to the probability for the positive class\n",
    "    y_scores = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    ### Confusion Matrix\n",
    "    confusion_matrix_test_object = confusion_matrix(y_test, test_pred)\n",
    "                \n",
    "    # Initialize a dictionary to store the metrics we are interested in\n",
    "    metrics_dict = Counter()\n",
    "\n",
    "    # These are all the basic threshold-dependent metrics\n",
    "    metrics_dict['Accuracy']  = float(\"{0:.4f}\".format(accuracy_score(y_test, test_pred)))\n",
    "\n",
    "    # The following are more useful than the accuracy\n",
    "    metrics_dict['Precision'] = float(\"{0:.4f}\".format(precision_score(y_test, test_pred, average='macro')))\n",
    "    metrics_dict['Recall'] = float(\"{0:.4f}\".format(recall_score(y_test, test_pred, average='macro')))\n",
    "    metrics_dict['F1'] = float(\"{0:.4f}\".format(f1_score(y_test, test_pred, average='macro')))\n",
    "\n",
    "    metrics_dict['TN'] = confusion_matrix_test_object[0][0]\n",
    "    metrics_dict['TP'] = confusion_matrix_test_object[1][1]\n",
    "    metrics_dict['FN'] = confusion_matrix_test_object[1][0]\n",
    "    metrics_dict['FP'] = confusion_matrix_test_object[0][1]\n",
    "\n",
    "    # These two are threshold-invariant metrics\n",
    "    metrics_dict['ROC AUC'] = float(\"{0:.4f}\".format(roc_auc_score(y_test, y_scores)))\n",
    "    metrics_dict['Average_Precision'] = float(\"{0:.4f}\".format(\n",
    "                                        average_precision_score(y_test, y_scores, average='macro', sample_weight=None)))\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     56864\n",
      "       Fraud       0.94      0.82      0.87        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.91      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'Accuracy': 0.9996,\n",
       "         'Precision': 0.9704,\n",
       "         'Recall': 0.9081,\n",
       "         'F1': 0.9371,\n",
       "         'TN': 56859,\n",
       "         'TP': 80,\n",
       "         'FN': 18,\n",
       "         'FP': 5,\n",
       "         'ROC AUC': 0.963,\n",
       "         'Average_Precision': 0.8734})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a classifier object with default params\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "custom_classification_metrics_function(X_test, y_test, labels, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So which metric would you use to compare? Depends on the business problem. If detecting the minority class is needed, ROC AUC and F1 score may not be the right metrics for imbalanced datasets\n",
    "https://towardsdatascience.com/selecting-the-right-metric-for-skewed-classification-problems-6e0a4a6167a7\n",
    "\n",
    "The F1 score is sensitive to imbalance but its unable to differentiate between a good recall or a good precision\n",
    "due to the symmetrical nature of the formula \n",
    "F1 = 2*(Precision * Recall)/(Precision + Recall)\n",
    "\n",
    "A robust metric that is invariant of the threshold chosen is the Average Precision which accounts for all the different thresholds\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='632'>Model Comparison </a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Average_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy Precision Recall   F1 ROC AUC   FN   TP   FP   TN  \\\n",
       "logreg             NaN       NaN    NaN  NaN     NaN  NaN  NaN  NaN  NaN   \n",
       "random_forest      NaN       NaN    NaN  NaN     NaN  NaN  NaN  NaN  NaN   \n",
       "naive_bayes        NaN       NaN    NaN  NaN     NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "              Average_Precision  \n",
       "logreg                      NaN  \n",
       "random_forest               NaN  \n",
       "naive_bayes                 NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets repeat the same for 2 other classifiers, the logistic_regression and the naive bayes\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize a classifier to initialize the classifier object \n",
    "classifier_dict = {'logreg':LogisticRegression(random_state=42), \n",
    "                   'random_forest':RandomForestClassifier(random_state=42), \n",
    "                   'naive_bayes':GaussianNB()}\n",
    "\n",
    "# Initialize a dataframe with the columns that we want to store being the various metrics of interest\n",
    "metrics_df = pd.DataFrame(\n",
    "columns = ['Accuracy','Precision','Recall','F1',\n",
    "           'ROC AUC','FN','TP','FP','TN','Average_Precision'],\n",
    "index = [classifier_name for classifier_name in classifier_dict.keys()])\n",
    "\n",
    "metrics_df\n",
    "# As seen below, the rows are the names of the classifiers and the columns are the metrics of interest\n",
    "# These NaNs will be replaced with the values of the metrics when you train the model and predict on the test data next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********\n",
      "logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     56864\n",
      "       Fraud       0.72      0.72      0.72        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.86      0.86      0.86     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Counter({'TN': 56836, 'TP': 71, 'FP': 28, 'FN': 27, 'Accuracy': 0.999, 'ROC AUC': 0.9464, 'Recall': 0.862, 'F1': 0.8602, 'Precision': 0.8583, 'Average_Precision': 0.6357})\n",
      "***********\n",
      "random_forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00     56864\n",
      "       Fraud       0.94      0.82      0.87        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.91      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Counter({'TN': 56859, 'TP': 80, 'FN': 18, 'FP': 5, 'Accuracy': 0.9996, 'Precision': 0.9704, 'ROC AUC': 0.963, 'F1': 0.9371, 'Recall': 0.9081, 'Average_Precision': 0.8734})\n",
      "***********\n",
      "naive_bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      0.99      1.00     56864\n",
      "       Fraud       0.14      0.66      0.23        98\n",
      "\n",
      "    accuracy                           0.99     56962\n",
      "   macro avg       0.57      0.83      0.61     56962\n",
      "weighted avg       1.00      0.99      0.99     56962\n",
      "\n",
      "Counter({'TN': 56457, 'FP': 407, 'TP': 65, 'FN': 33, 'Accuracy': 0.9923, 'ROC AUC': 0.9677, 'Recall': 0.8281, 'F1': 0.6121, 'Precision': 0.5686, 'Average_Precision': 0.1824})\n"
     ]
    }
   ],
   "source": [
    "for classifier_name, classifier in classifier_dict.items(): \n",
    "    classifier.fit(X_train, y_train)\n",
    "    print('***********') \n",
    "    print(classifier_name) \n",
    "    metrics_dict = custom_classification_metrics_function(X_test, y_test, labels, classifier)\n",
    "    print(metrics_dict)\n",
    "    \n",
    "    # store the metrics as a single row in the dataframe against each classifier name\n",
    "    metrics_df.loc[classifier_name] = metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Average_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.8583</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>27.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56836.0</td>\n",
       "      <td>0.6357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.963</td>\n",
       "      <td>18.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56859.0</td>\n",
       "      <td>0.8734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.9923</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>56457.0</td>\n",
       "      <td>0.1824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy Precision  Recall      F1 ROC AUC    FN    TP     FP  \\\n",
       "logreg           0.999    0.8583   0.862  0.8602  0.9464  27.0  71.0   28.0   \n",
       "random_forest   0.9996    0.9704  0.9081  0.9371   0.963  18.0  80.0    5.0   \n",
       "naive_bayes     0.9923    0.5686  0.8281  0.6121  0.9677  33.0  65.0  407.0   \n",
       "\n",
       "                    TN Average_Precision  \n",
       "logreg         56836.0            0.6357  \n",
       "random_forest  56859.0            0.8734  \n",
       "naive_bayes    56457.0            0.1824  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seen the NB solution is by far the worst performer amongst the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over the course of the LiveProject, you will be repeatedly using the custom_classification_metrics_function to determine the accuracy metrics (with slight modifications when using the PyOD API) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
