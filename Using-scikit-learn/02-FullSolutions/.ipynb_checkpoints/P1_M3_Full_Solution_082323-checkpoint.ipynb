{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Stylianos Kampakis & Shreesha Jagadeesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the full solution for Project 1 until the end of Milestone 4 for Novelty Detection using Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a> <br>\n",
    "## Table of  Contents\n",
    "1. [Introduction](#1)\n",
    "\n",
    "1. [Initialization](#2)\n",
    "    1. [Load packages](#21)\n",
    "    1. [Define Metadata](#22)\n",
    "    \n",
    "1. [Load Data](#3)\n",
    "\n",
    "1. [Data Insights](#4)\n",
    "    1. [Data Structure](#41)\n",
    "    1. [Summary Stats](#42)\n",
    "    1. [Unique Value Checking](#43)\n",
    "    1. [Identifying 'Bad Columns'](#44)\n",
    "\n",
    "1. [Data Cleansing](#5)\n",
    "    1. [Data Reduction](#51)\n",
    "        1. [Dropping Bad Columns](#511)\n",
    "        1. [Null Value Removal](#512)\n",
    "        1. [Data Encoding](#513)\n",
    "    1. [Export csv file for later use](#52)\n",
    "\n",
    "1. [Modelling Workflow](#6)\n",
    "    1. [Data Prep](#61)\n",
    "        1. [Feature Target Split](#611)\n",
    "        1. [Train-Test Split](#612)\n",
    "        1. [Normalizing Numerical Variables](#613)\n",
    "    1. [Estimate of Baseline Accuracy - Class Distributions](#62)\n",
    "    1. [Semisupervised & Unsupervised Techniques for Novelty & Outlier Detection](#63)\n",
    "        1. [OneClassSVMs for Novelty Detection](#631)\n",
    "        1. [Robust Covariance for Outlier Detection](#632)\n",
    "        1. [Isolation Forest for Novelty Detection](#633)\n",
    "        1. [Local Outlier Factor for Novelty Detection](#634)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='1'>Introduction</a>  \n",
    "\n",
    "As described on the project page, the dataset contains the Thyroid disease data that is imbalanced. Before running this notebook, please make sure that you have gone through the first project in the LiveSeries and the starter template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2'>Initialization</a>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='21'>Load Packages</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the minimum number of packages to get started and add more as we go along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "from scipy.io.arff import loadarff\n",
    "import scipy.io as sio\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix \n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='22'>Define Metadata</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the target class column here instead of manually typing it out everywhere\n",
    "target_class_name = 6\n",
    "\n",
    "# Fill in the names of what you want to call the 0 and 1 class\n",
    "labels = ['inliers', 'outliers']\n",
    "\n",
    "# The following file is downloaded from http://odds.cs.stonybrook.edu/thyroid-disease-dataset/ and kept in the data/raw folder\n",
    "input_file_name = 'thyroid.mat'\n",
    "\n",
    "# Using relative path path to specify that the data subfolder is two directories up from the current folder \n",
    "raw_data_folder = '../../data/raw/'\n",
    "processed_data_folder = '../../data/processed/'\n",
    "\n",
    "# Any exported artifacts will have this date\n",
    "export_date = '20211101'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3'>Load Data</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will load the data and perform some necessary preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, written by Octave 3.8.0, 2014-12-05 13:11:25 UTC',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[7.74193548e-01, 1.13207547e-03, 1.37571157e-01, 2.75700935e-01,\n",
       "         2.95774648e-01, 2.36065574e-01],\n",
       "        [2.47311828e-01, 4.71698113e-04, 2.79886148e-01, 3.29439252e-01,\n",
       "         5.35211268e-01, 1.73770492e-01],\n",
       "        [4.94623656e-01, 3.58490566e-03, 2.22960152e-01, 2.33644860e-01,\n",
       "         5.25821596e-01, 1.24590164e-01],\n",
       "        ...,\n",
       "        [9.35483871e-01, 2.45283019e-02, 1.60341556e-01, 2.82710280e-01,\n",
       "         3.75586854e-01, 2.00000000e-01],\n",
       "        [6.77419355e-01, 1.47169811e-03, 1.90702087e-01, 2.42990654e-01,\n",
       "         3.23943662e-01, 1.95081967e-01],\n",
       "        [4.83870968e-01, 3.56603774e-03, 1.90702087e-01, 2.12616822e-01,\n",
       "         3.38028169e-01, 1.63934426e-01]]),\n",
       " 'y': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=sio.loadmat(raw_data_folder + input_file_name)\n",
    "\n",
    "data\n",
    "# This is an interesting format with the metadata available as header, version and globals while the features are given \n",
    "# in the X array and the y \n",
    "\n",
    "# There appears to be 6 attributes in X, all numerical \n",
    "# The y values seems to be already encoded as numbers too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3772, 6), (3772, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the features and target objects in their own variables for easy retreival\n",
    "X=data['X']\n",
    "y=data['y']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.061670</td>\n",
       "      <td>0.196262</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.193443</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.214953</td>\n",
       "      <td>0.389671</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.214953</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.160656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.261682</td>\n",
       "      <td>0.347418</td>\n",
       "      <td>0.198361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0.179907</td>\n",
       "      <td>0.286385</td>\n",
       "      <td>0.157377</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5    6\n",
       "2261  0.666667  0.012264  0.061670  0.196262  0.248826  0.193443  0.0\n",
       "2699  0.838710  0.010566  0.137571  0.214953  0.389671  0.147541  0.0\n",
       "1939  0.161290  0.006792  0.241935  0.214953  0.352113  0.160656  0.0\n",
       "1304  0.580645  0.003019  0.147059  0.261682  0.347418  0.198361  0.0\n",
       "1118  0.741935  0.002830  0.023719  0.179907  0.286385  0.157377  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a dataframe\n",
    "df=pd.DataFrame((np.concatenate((X, y), axis=1)))\n",
    "\n",
    "# Take a random sample to see how the data looks like\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the head & tail to make sure there is nothing going on at the last row or the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.137571</td>\n",
       "      <td>0.275701</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.236066</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247312</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.279886</td>\n",
       "      <td>0.329439</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.173770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.222960</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>0.525822</td>\n",
       "      <td>0.124590</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5    6\n",
       "0  0.774194  0.001132  0.137571  0.275701  0.295775  0.236066  0.0\n",
       "1  0.247312  0.000472  0.279886  0.329439  0.535211  0.173770  0.0\n",
       "2  0.494624  0.003585  0.222960  0.233645  0.525822  0.124590  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.160342</td>\n",
       "      <td>0.282710</td>\n",
       "      <td>0.375587</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.190702</td>\n",
       "      <td>0.242991</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.195082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.190702</td>\n",
       "      <td>0.212617</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5    6\n",
       "3769  0.935484  0.024528  0.160342  0.282710  0.375587  0.200000  0.0\n",
       "3770  0.677419  0.001472  0.190702  0.242991  0.323944  0.195082  0.0\n",
       "3771  0.483871  0.003566  0.190702  0.212617  0.338028  0.163934  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No trouble with loading the data. Both the head and tail are clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=4 > Data Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='41'>Data Structure</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3772 entries, 0 to 3771\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       3772 non-null   float64\n",
      " 1   1       3772 non-null   float64\n",
      " 2   2       3772 non-null   float64\n",
      " 3   3       3772 non-null   float64\n",
      " 4   4       3772 non-null   float64\n",
      " 5   5       3772 non-null   float64\n",
      " 6   6       3772 non-null   float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 206.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Lets see the data structure\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the columns have null values at first glance, but we will run a more thorough diagnostic later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='42'>Summary Stats</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out each column's summary statistics\n",
    "Note that only the numerical columns will be described\n",
    "Also you will want to exclude the discrete columns whose summary stats will give non-sensical values like 'customer_id' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3772.000000</td>\n",
       "      <td>3772.000000</td>\n",
       "      <td>3772.000000</td>\n",
       "      <td>3772.000000</td>\n",
       "      <td>3772.000000</td>\n",
       "      <td>3772.000000</td>\n",
       "      <td>3772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.543121</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.186826</td>\n",
       "      <td>0.248332</td>\n",
       "      <td>0.376941</td>\n",
       "      <td>0.177301</td>\n",
       "      <td>0.024655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.203790</td>\n",
       "      <td>0.043978</td>\n",
       "      <td>0.070405</td>\n",
       "      <td>0.080579</td>\n",
       "      <td>0.087382</td>\n",
       "      <td>0.054907</td>\n",
       "      <td>0.155093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.376344</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.156546</td>\n",
       "      <td>0.203271</td>\n",
       "      <td>0.328638</td>\n",
       "      <td>0.149180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.190702</td>\n",
       "      <td>0.241822</td>\n",
       "      <td>0.375587</td>\n",
       "      <td>0.173770</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.213472</td>\n",
       "      <td>0.282710</td>\n",
       "      <td>0.413146</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  3772.000000  3772.000000  3772.000000  3772.000000  3772.000000   \n",
       "mean      0.543121     0.008983     0.186826     0.248332     0.376941   \n",
       "std       0.203790     0.043978     0.070405     0.080579     0.087382   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.376344     0.001132     0.156546     0.203271     0.328638   \n",
       "50%       0.569892     0.003019     0.190702     0.241822     0.375587   \n",
       "75%       0.709677     0.004528     0.213472     0.282710     0.413146   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                 5            6  \n",
       "count  3772.000000  3772.000000  \n",
       "mean      0.177301     0.024655  \n",
       "std       0.054907     0.155093  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.149180     0.000000  \n",
       "50%       0.173770     0.000000  \n",
       "75%       0.196721     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "# Looks like all the numbers are between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='43'>Unique Value Checking</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 93\n",
      "1 280\n",
      "2 72\n",
      "3 243\n",
      "4 141\n",
      "5 324\n",
      "6 2\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(column, len(df[column].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns have atleast 2 unique values, hence there is less of a chance of quasi-constant values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='44'>Identifying Bad Columns</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_columns_function(dataframe):\n",
    "    '''\n",
    "    Args: dataframe for which there maybe columns of concern that need to be fixed or deleted\n",
    "    \n",
    "    Logic: Find the columns that have \n",
    "    Null values\n",
    "    blanks in the strings\n",
    "    quasi constant/constant values defined by less than 1% variance\n",
    "    \n",
    "    Returns: 4 lists containing those features that have nulls, blanks, constant values throughout for numerical and categorical\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ###### Finding Null Values\n",
    "    null_col_list = dataframe.columns[dataframe.isna().any()].tolist()\n",
    "    \n",
    "    print('Identified {} features with atleast one null'.format(\n",
    "        len(null_col_list)))\n",
    "\n",
    "    ###### Finding Blank Spaces in the object column\n",
    "    # Non-obvious nulls such as blanks: The line items where there are spaces \n",
    "    blank_space_col_list = []\n",
    "    object_columns = dataframe.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in object_columns:\n",
    "        if sum(dataframe[col]==' '):\n",
    "            blank_space_col_list.append(col)\n",
    "\n",
    "    print('Identified {} features with atleast one blank space'.format(\n",
    "        len(blank_space_col_list)))\n",
    "    \n",
    "    ####### Finding Quasi Constant/Constant Value in numerical columns\n",
    "    # Lets remove the variables that have more than 99% of their values as the same \n",
    "    # ie their standard deviation is less than 1 %\n",
    "    \n",
    "    numeric_df = dataframe._get_numeric_data()\n",
    "    constant_numeric_col_list = [col for col in numeric_df.columns if numeric_df[col].std()<0.01]\n",
    "\n",
    "    print('Identified {} numeric features that have quasi-constant values'.format(\n",
    "        len(constant_numeric_col_list)))\n",
    "    \n",
    "    # We use a separate logic for the non-numerical variables because if you have closely varying float values\n",
    "    # then the below code snippet wont pick it up\n",
    "    \n",
    "    ###### Finding Quasi Constant/Constant non_numeric value\n",
    "    constant_non_numeric_col_list = []\n",
    "    \n",
    "    # Find the columns that are not in numeric_df\n",
    "    non_numeric_col_set = set(dataframe.columns) - set(numeric_df.columns)   \n",
    "\n",
    "    for col in non_numeric_col_set:\n",
    "        categorical_mode_value = (dataframe[col].mode().values)[0]\n",
    "        fractional_presence = sum(dataframe[col]==categorical_mode_value)/len(dataframe) \n",
    "    \n",
    "        if fractional_presence > 0.99:\n",
    "            constant_non_numeric_col_list.append(col)\n",
    "            \n",
    "    print('Identified {} non-numeric features that have quasi-constant values'.format(\n",
    "        len(constant_non_numeric_col_list)))\n",
    "    \n",
    "    return null_col_list, blank_space_col_list, constant_numeric_col_list, constant_non_numeric_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 features with atleast one null\n",
      "Identified 0 features with atleast one blank space\n",
      "Identified 0 numeric features that have quasi-constant values\n",
      "Identified 0 non-numeric features that have quasi-constant values\n"
     ]
    }
   ],
   "source": [
    "# use the above custom function to figure out the if there are any columns we need to be concerned about\n",
    "null_col_list, blank_space_col_list, constant_numeric_col_list, \\\n",
    "constant_non_numeric_col_list = find_bad_columns_function(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, there is no need to worry about any of the columns in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5'>Data Cleansing</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='51'>Data Reduction</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='511'>Dropping Bad Columns</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this because there are no columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='512'>Null Value Removal</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null values to drop from the rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='513'>Data Encoding</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    float64\n",
       "1    float64\n",
       "2    float64\n",
       "3    float64\n",
       "4    float64\n",
       "5    float64\n",
       "6    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no categorical variables to encode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='52'>Export cleaned csv file for later use</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a backup copy of the processed dataframe \n",
    "# so that you don't need to run the entire notebook again just to get to the next stage\n",
    "\n",
    "cleaned_dataframe_name='cleaned_thryoid_dataframe'\n",
    "df.to_csv(processed_data_folder + cleaned_dataframe_name + export_date + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 1 Ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 2 Begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = 6 > Modelling Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 61 > Data Prep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='611'>Feature - Target Split</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3772, 6)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(target_class_name, axis=1)\n",
    "y = df[target_class_name]\n",
    "\n",
    "print(X.shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='612'>Train-Test Split</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3017, 6) (755, 6) 74 19\n"
     ]
    }
   ],
   "source": [
    "# split into train and test set and \n",
    "# make sure that the stratification is done so that roughly proportional instances of the minority class is present in the train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# These are the original dimensions and the outlier class occurrences \n",
    "print(X_train.shape, X_test.shape, sum(y_train==1), sum(y_test==1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = 613 > Normalizing numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not needed here because the variables are already scaled between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='62'>Estimate of baseline accuracy - Class Distributions </a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of inliers is 97.534 %\n",
      "Percentage of outliers is 2.466 %\n"
     ]
    }
   ],
   "source": [
    "# Figure out the class distribution percentage and round it to 3 decimal places\n",
    "\n",
    "print('Percentage of inliers is {} %'.format(\n",
    "    round(df[target_class_name].value_counts()[0]/len(df) * 100,3)))\n",
    "\n",
    "print('Percentage of outliers is {} %'.format(\n",
    "    round(df[target_class_name].value_counts()[1]/len(df) * 100,3)))\n",
    "\n",
    "# A dumb model that predicts everything as being 0, will generate a baseline accuracy of 97.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3679\n",
       "1.0      93\n",
       "Name: 6, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "pd.value_counts(df[target_class_name]).plot.bar()\n",
    "plt.title('Histogram of class distributions')\n",
    "plt.xlabel(labels[1])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Frequency')\n",
    "df[target_class_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy to beat is 97.5% if you predict everything as being 0 (i.e. the majority class)\n",
    "\n",
    "What about the other metrics like Precision, Recall and F1 score? They would all be 0% because there will be no True Positives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the number of outliers that we observe in the overall dataset. \n",
    "outliers_fraction=0.025\n",
    "\n",
    "#We will use a multiple of this as the nu or contamination factor to tell the model how many to expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='63'> Scikit Learn Algorithms for Novelty & Outlier Detection </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Why do we need specialized techniques for Anomaly Detection rather than just use binary classification algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to binary classification problems, the minority class, i.e. the anomalies, are quite rare and often different from each other. So the usual binary classification algorithms fail to 'learn' a representation of the minority class. We will attempt to use binary classification methdods with resampling techniques that balance out the distributions of the 2 classes in projects 2 & 3 but in this Project we will focus on out-of-the-box Anomaly detection algorithms provided by Scikit Learn\n",
    "\n",
    "The previous plot of class distributions gave an indication of how rare our samples are and this warrants these special techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference between Novelty, Outliers and Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many use cases, the differences between them are irrelevant. As long as the sample is 'sufficiently' different, we can call them whatever we want. However there are specialized use cases where huge performance gains can be achieved by using a semi-supervised technique of Novelty Detection vs completely unsupervised Outlier Detection. Hence it is important to understand what the differences are\n",
    "\n",
    "Novelty Detection: The training data is not polluted by outliers and we are interested in detecting whether a new observation is an outlier. In this context an outlier is also called a novelty. This would mean that our input train data during model fitting cannot contain the minority class. \n",
    "\n",
    "Outlier Detection: The training data contains outliers which are defined as observations that are far from the others. Outlier detection estimators thus try to fit the regions where the training data is the most concentrated, ignoring the deviant observations.\n",
    "\n",
    "Both Novelties and Outlier samples are referred to as the Anomalies\n",
    "\n",
    "Further details are in the sklearn documentation page\n",
    "https://scikit-learn.org/stable/modules/outlier_detection.html#outlier-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following milestones, we will explore applying both types of algorithms on our training dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='631'>OneClassSVMs for Novelty Detection</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to semi-supervised approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem solved by OneClassSVM is for novelty detection using an semi-supervised approach\n",
    "\n",
    "As Leo Tolstoy said ‘All happy families are alike; each unhappy family is unhappy in its own way.’\n",
    "The implication for our use case is that OneClassSVM excels in situations where the inliers are all alike but the outliers are all special snowflakes. Datasets that have such as issue prevents the use of traditional 2-class binary classification problems and instead we use a 'unary' classification problem. Only the statistics of normal operation are known from the inliers\n",
    "\n",
    "We will be using OneClassSVM in a similar manner as unsupervised clustering. The approach processes the data as a static\n",
    "distribution, pinpoints the most remote points, and flags them as potential outliers. \n",
    "\n",
    "The main assumption on the data is that the outliers are actually separated from the inliers and hence the OCSVM algorithm can indeed separate it out. \n",
    "\n",
    "The main thing to note is that deleting the minority class from the input train data improves the performance when the model later sees the outliers mixed in with normal inliers. This would be a case of semi-supervised because we are using the labels but not necessarily to fit the model but to remove the minority class samples to improve the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://proceedings.neurips.cc/paper/1999/file/8725fb777f25776ffa9076e44fcfd776-Paper.pdf\n",
    "\n",
    "https://en.wikipedia.org/wiki/One-class_classification\n",
    "\n",
    "https://eprints.whiterose.ac.uk/767/1/hodgevj4.pdf\n",
    "\n",
    "https://www.datatechnotes.com/2020/04/anomaly-detection-with-one-class-svm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to hold the binary classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse the same function from the starter template\n",
    "def custom_classification_metrics_function(X_test, y_test, labels, classifier):\n",
    "    '''\n",
    "    Args: The features and the target column; the labels are the categories, sklearn classifier object\n",
    "    Calculates Classification metrics of interest\n",
    "    Returns: A dictionary containing the classification metrics\n",
    "    '''\n",
    "\n",
    "    # Generate the predictions on the test data which forms the basis of the evaluation metrics\n",
    "    test_pred = classifier.predict(X_test)\n",
    "        \n",
    "    # This is to convert the output labels so that the confusion matrix and the accuracy scores work correctly\n",
    "    # The anomalies identified by sklearn are labelled as -1 but we want them to recognized as 1, so we flip the labels\n",
    "    test_pred = test_pred*-1\n",
    "    test_pred[test_pred==-1]=0\n",
    "    \n",
    "    ### Classification report\n",
    "    print(classification_report(y_test, test_pred, target_names=labels))\n",
    "\n",
    "    ### Probability scores\n",
    "    \n",
    "    # Unlike the usual classifiers, Anomaly detection algorithms don't have a predict_proba() method that can be applied\n",
    "    # Instead we have to get the raw scores from the decision function applied on the test data\n",
    "    decision_score_list = classifier.decision_function(X_test)\n",
    "    \n",
    "    # ......and turn them into numbers between 0 and 1 which can be treated as probabilities\n",
    "    scaled_decision_score_list = MinMaxScaler().fit_transform(decision_score_list.reshape(-1, 1))\n",
    "\n",
    "    # This is just to flatten the list and subtract the no.s so that the outliers are closer to 1 rather than 0\n",
    "    y_scores = [1-item for sublist in scaled_decision_score_list for item in sublist]\n",
    "\n",
    "\n",
    "    ### Confusion Matrix\n",
    "    confusion_matrix_test_object = confusion_matrix(y_test, test_pred)\n",
    "                \n",
    "    # Initialize a dictionary to store the metrics we are interested in\n",
    "    metrics_dict = Counter()\n",
    "\n",
    "    # These are all the basic threshold-dependent metrics\n",
    "    metrics_dict['Accuracy']  = float(\"{0:.4f}\".format(accuracy_score(y_test, test_pred)))\n",
    "\n",
    "    # The following are more useful than the accuracy\n",
    "    metrics_dict['Precision'] = float(\"{0:.4f}\".format(precision_score(y_test, test_pred, average='macro')))\n",
    "    metrics_dict['Recall'] = float(\"{0:.4f}\".format(recall_score(y_test, test_pred, average='macro')))\n",
    "    metrics_dict['F1'] = float(\"{0:.4f}\".format(f1_score(y_test, test_pred, average='macro')))\n",
    "\n",
    "    metrics_dict['TN'] = confusion_matrix_test_object[0][0]\n",
    "    metrics_dict['TP'] = confusion_matrix_test_object[1][1]\n",
    "    metrics_dict['FN'] = confusion_matrix_test_object[1][0]\n",
    "    metrics_dict['FP'] = confusion_matrix_test_object[0][1]\n",
    "\n",
    "    # These two are threshold-invariant metrics\n",
    "    metrics_dict['ROC AUC'] = float(\"{0:.4f}\".format(roc_auc_score(y_test, y_scores)))\n",
    "    metrics_dict['Average_Precision'] = float(\"{0:.4f}\".format(\n",
    "                                        average_precision_score(y_test, y_scores, average='macro', sample_weight=None)))\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep train data for one class novelty detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2943, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate X_train with y_train. Then filter out the samples that we know are outliers\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "inlier_X_train = df_train[df_train[target_class_name]==0].drop(target_class_name, axis=1)\n",
    "\n",
    "# We will use inlier_X_train as the input dataset\n",
    "inlier_X_train.shape\n",
    "# That makes sense to have 3017 - 74= 2943 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize dictionaries to store the instantiated models and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 3 SVM models with different parameters to get a sense of the performance across the metrics of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Average_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM RBF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM poly degree 2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM poly degree 3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy Precision Recall   F1 ROC AUC   FN   TP  \\\n",
       "Novelty OCSVM RBF                NaN       NaN    NaN  NaN     NaN  NaN  NaN   \n",
       "Novelty OCSVM poly degree 2      NaN       NaN    NaN  NaN     NaN  NaN  NaN   \n",
       "Novelty OCSVM poly degree 3      NaN       NaN    NaN  NaN     NaN  NaN  NaN   \n",
       "\n",
       "                              FP   TN Average_Precision  \n",
       "Novelty OCSVM RBF            NaN  NaN               NaN  \n",
       "Novelty OCSVM poly degree 2  NaN  NaN               NaN  \n",
       "Novelty OCSVM poly degree 3  NaN  NaN               NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a dictionary to store the variants of the model with different kernel types\n",
    "# Add a prefix Novelty' to indicate that our training method relies on a pure sample of inliers\n",
    "classifier_dict = {\"Novelty OCSVM RBF\":OneClassSVM(nu=outliers_fraction*4, kernel=\"rbf\"), \n",
    "                   \"Novelty OCSVM poly degree 2\":OneClassSVM(nu=outliers_fraction*4, kernel=\"poly\", degree=2),\n",
    "                   \"Novelty OCSVM poly degree 3\":OneClassSVM(nu=outliers_fraction*4, kernel=\"poly\",degree=3)}\n",
    "\n",
    "# nu is a hyperparameter in the model that controls the upper bound of the training error. \n",
    "# nu is usually set empirically (can also be tuned by hyperparameter tunning).\n",
    "\n",
    "# Note: though the actual no. of outliers in the train data is 2.5%, due to the inherent inaccuracies, \n",
    "# it makes sense to intentionally tell the model to look for more outliers than is the case to increase Precision\n",
    "# This of course increases the False Positives but that is a tradeoff worth making when detection of rare diseases is needed\n",
    "\n",
    "# Initialize a dataframe with the columns that we want to store being the various metrics of interest\n",
    "metrics_df = pd.DataFrame(\n",
    "columns = ['Accuracy','Precision','Recall','F1', 'ROC AUC', \n",
    "           'FN','TP','FP','TN', 'Average_Precision'],\n",
    "index = [classifier_name for classifier_name in classifier_dict.keys()])\n",
    "\n",
    "metrics_df\n",
    "# As seen below, the rows are the names of the classifiers and the columns are the metrics of interest\n",
    "# These NaNs will be replaced with the values of the metrics when you train the model and predict on the test data next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientists working on skewed data problems need to keep in mind a) Defining & capturing the right metrics and b) Interpreting metrics\n",
    "\n",
    "Defining & capturing the right metrics: In the custom classification metrics function, we have intentionally captured the macro averaged metrics for the Precision, Recall, F1, Average Precision scores. Specifying the macro version ensures that sklearn corrects for the skewed data and weights both classes equally. \n",
    "\n",
    "Interpreting metrics: The correct interpretation relies on the use case and there is no one size fits all. In the case of outlier detection like Thyroid detection, we would typically want as much of the positive instances (in this case the outlier class) to be captured at the expense of having more False Positives \n",
    "This is because even if there are False Positives, a detailed screening can clear them out, but if a patient's case is not detected at all (i.e. False Negatives), then they are sent home and lost to follow-up evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the various classifiers and store the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********\n",
      "Novelty OCSVM RBF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     inliers       0.99      0.92      0.95       736\n",
      "    outliers       0.19      0.74      0.30        19\n",
      "\n",
      "    accuracy                           0.91       755\n",
      "   macro avg       0.59      0.83      0.63       755\n",
      "weighted avg       0.97      0.91      0.94       755\n",
      "\n",
      "Counter({'TN': 676, 'FP': 60, 'TP': 14, 'FN': 5, 'ROC AUC': 0.9489, 'Accuracy': 0.9139, 'Recall': 0.8277, 'F1': 0.6276, 'Precision': 0.5909, 'Average_Precision': 0.4337})\n",
      "***********\n",
      "Novelty OCSVM poly degree 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     inliers       0.98      0.91      0.94       736\n",
      "    outliers       0.10      0.42      0.17        19\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.54      0.66      0.56       755\n",
      "weighted avg       0.96      0.89      0.92       755\n",
      "\n",
      "Counter({'TN': 667, 'FP': 69, 'FN': 11, 'TP': 8, 'Accuracy': 0.894, 'ROC AUC': 0.7966, 'Recall': 0.6637, 'F1': 0.555, 'Precision': 0.5438, 'Average_Precision': 0.2202})\n",
      "***********\n",
      "Novelty OCSVM poly degree 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     inliers       0.98      0.91      0.94       736\n",
      "    outliers       0.10      0.42      0.17        19\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.54      0.66      0.56       755\n",
      "weighted avg       0.96      0.89      0.92       755\n",
      "\n",
      "Counter({'TN': 667, 'FP': 69, 'FN': 11, 'TP': 8, 'Accuracy': 0.894, 'ROC AUC': 0.7953, 'Recall': 0.6637, 'F1': 0.555, 'Precision': 0.5438, 'Average_Precision': 0.2244})\n"
     ]
    }
   ],
   "source": [
    "for classifier_name, classifier in classifier_dict.items(): \n",
    "    \n",
    "    # Replace the X_train with inlier_X_train for one-class novelty training\n",
    "    classifier.fit(inlier_X_train)\n",
    "    print('***********') \n",
    "    print(classifier_name) \n",
    "    metrics_dict = custom_classification_metrics_function(X_test, y_test, labels, classifier)\n",
    "    print(metrics_dict)\n",
    "    \n",
    "    # store the metrics as a single row in the dataframe against each classifier name\n",
    "    metrics_df.loc[classifier_name] = metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Average_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM RBF</th>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>0.6276</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>676</td>\n",
       "      <td>0.4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM poly degree 2</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>667</td>\n",
       "      <td>0.2202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM poly degree 3</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>667</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy Precision  Recall      F1 ROC AUC  FN  \\\n",
       "Novelty OCSVM RBF             0.9139    0.5909  0.8277  0.6276  0.9489   5   \n",
       "Novelty OCSVM poly degree 2    0.894    0.5438  0.6637   0.555  0.7966  11   \n",
       "Novelty OCSVM poly degree 3    0.894    0.5438  0.6637   0.555  0.7953  11   \n",
       "\n",
       "                             TP  FP   TN Average_Precision  \n",
       "Novelty OCSVM RBF            14  60  676            0.4337  \n",
       "Novelty OCSVM poly degree 2   8  69  667            0.2202  \n",
       "Novelty OCSVM poly degree 3   8  69  667            0.2244  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df\n",
    "# Note that the Precision, Recall, F1 score are macro averaged metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our use case in detecting thyroid anomalies, we would want a model that has a relatively high Recall to not miss out on  outliers (i.e. fewer False Negatives). The OCSVM with RBF kernel has the best Recall while being reasonable with the no. of False Positives relative to the polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Average_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM RBF</th>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>0.6276</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>676</td>\n",
       "      <td>0.4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM poly degree 2</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>667</td>\n",
       "      <td>0.2202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM poly degree 3</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>667</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy Precision  Recall      F1 ROC AUC  FN  \\\n",
       "Novelty OCSVM RBF             0.9139    0.5909  0.8277  0.6276  0.9489   5   \n",
       "Novelty OCSVM poly degree 2    0.894    0.5438  0.6637   0.555  0.7966  11   \n",
       "Novelty OCSVM poly degree 3    0.894    0.5438  0.6637   0.555  0.7953  11   \n",
       "\n",
       "                             TP  FP   TN Average_Precision  \n",
       "Novelty OCSVM RBF            14  60  676            0.4337  \n",
       "Novelty OCSVM poly degree 2   8  69  667            0.2202  \n",
       "Novelty OCSVM poly degree 3   8  69  667            0.2244  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_metrics_df = metrics_df.copy()\n",
    "cumulative_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 2 Ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 3 Begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='632'> Robust Covariance for Outlier Detection </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EllipticEnvelope assumes the data is Gaussian and learns an ellipse to fit the inliers. The ellipse refers to how a 2D Gaussian distribution would look like when viewed from the top. Its called 'Robust' because learning the ellipse is not influenced by the outliers present in the data. The distance of an observation to the mode of the distribution obtained from this estimate is used to derive a measure of 'outlyingness.' \n",
    "\n",
    "Caveats: This method will not give good results when the number of samples does not exceed the squared of the features. In our case, we have 6 features and have 1000s of samples so we won't run into this limitation. Also, if your data is very non-Gaussian, then the method will not clearly work well.\n",
    "\n",
    "Reference\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html#sklearn.covariance.EllipticEnvelope\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/covariance/plot_mahalanobis_distances.html#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py\n",
    "\n",
    "https://sdsawtelle.github.io/blog/output/week9-anomaly-andrew-ng-machine-learning-with-python.html\n",
    "(The last article also has code for how to do GridSearchCV on the outlier_fraction with a custom make_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize dataframe store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Average_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 4x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 2x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 1x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Accuracy Precision Recall   F1 ROC AUC   FN  \\\n",
       "Robust covariance outliers 4x      NaN       NaN    NaN  NaN     NaN  NaN   \n",
       "Robust covariance outliers 2x      NaN       NaN    NaN  NaN     NaN  NaN   \n",
       "Robust covariance outliers 1x      NaN       NaN    NaN  NaN     NaN  NaN   \n",
       "\n",
       "                                TP   FP   TN Average_Precision  \n",
       "Robust covariance outliers 4x  NaN  NaN  NaN               NaN  \n",
       "Robust covariance outliers 2x  NaN  NaN  NaN               NaN  \n",
       "Robust covariance outliers 1x  NaN  NaN  NaN               NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_dict ={\n",
    "    \"Robust covariance outliers 4x\": EllipticEnvelope(contamination=outliers_fraction*4),\n",
    "    \"Robust covariance outliers 2x\": EllipticEnvelope(contamination=outliers_fraction*2),\n",
    "    \"Robust covariance outliers 1x\": EllipticEnvelope(contamination=outliers_fraction)\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(\n",
    "columns = ['Accuracy','Precision','Recall','F1', 'ROC AUC', \n",
    "           'FN','TP','FP','TN', 'Average_Precision'],\n",
    "index = [classifier_name for classifier_name in classifier_dict.keys()])\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the various classifiers and store the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********\n",
      "Robust covariance outliers 4x\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     inliers       1.00      0.93      0.96       736\n",
      "    outliers       0.27      0.95      0.42        19\n",
      "\n",
      "    accuracy                           0.93       755\n",
      "   macro avg       0.63      0.94      0.69       755\n",
      "weighted avg       0.98      0.93      0.95       755\n",
      "\n",
      "Counter({'TN': 687, 'FP': 49, 'TP': 18, 'FN': 1, 'ROC AUC': 0.9859, 'Recall': 0.9404, 'Accuracy': 0.9338, 'Average_Precision': 0.7766, 'F1': 0.6917, 'Precision': 0.6336})\n",
      "***********\n",
      "Robust covariance outliers 2x\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     inliers       1.00      0.98      0.99       736\n",
      "    outliers       0.57      0.89      0.69        19\n",
      "\n",
      "    accuracy                           0.98       755\n",
      "   macro avg       0.78      0.94      0.84       755\n",
      "weighted avg       0.99      0.98      0.98       755\n",
      "\n",
      "Counter({'TN': 723, 'TP': 17, 'FP': 13, 'FN': 2, 'ROC AUC': 0.986, 'Accuracy': 0.9801, 'Recall': 0.9385, 'F1': 0.8418, 'Precision': 0.782, 'Average_Precision': 0.7763})\n",
      "***********\n",
      "Robust covariance outliers 1x\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     inliers       0.99      0.99      0.99       736\n",
      "    outliers       0.74      0.74      0.74        19\n",
      "\n",
      "    accuracy                           0.99       755\n",
      "   macro avg       0.87      0.87      0.87       755\n",
      "weighted avg       0.99      0.99      0.99       755\n",
      "\n",
      "Counter({'TN': 731, 'TP': 14, 'FN': 5, 'FP': 5, 'Accuracy': 0.9868, 'ROC AUC': 0.9861, 'Precision': 0.865, 'Recall': 0.865, 'F1': 0.865, 'Average_Precision': 0.7767})\n"
     ]
    }
   ],
   "source": [
    "for classifier_name, classifier in classifier_dict.items(): \n",
    "    classifier.fit(X_train)\n",
    "    print('***********') \n",
    "    print(classifier_name) \n",
    "    metrics_dict = custom_classification_metrics_function(X_test, y_test, labels, classifier)\n",
    "    print(metrics_dict)\n",
    "    \n",
    "    # store the metrics as a single row in the dataframe against each classifier name\n",
    "    metrics_df.loc[classifier_name] = metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Average_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 4x</th>\n",
       "      <td>0.9338</td>\n",
       "      <td>0.6336</td>\n",
       "      <td>0.9404</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>687</td>\n",
       "      <td>0.7766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 2x</th>\n",
       "      <td>0.9801</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>0.986</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>723</td>\n",
       "      <td>0.7763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 1x</th>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>731</td>\n",
       "      <td>0.7767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Accuracy Precision  Recall      F1 ROC AUC FN  \\\n",
       "Robust covariance outliers 4x   0.9338    0.6336  0.9404  0.6917  0.9859  1   \n",
       "Robust covariance outliers 2x   0.9801     0.782  0.9385  0.8418   0.986  2   \n",
       "Robust covariance outliers 1x   0.9868     0.865   0.865   0.865  0.9861  5   \n",
       "\n",
       "                               TP  FP   TN Average_Precision  \n",
       "Robust covariance outliers 4x  18  49  687            0.7766  \n",
       "Robust covariance outliers 2x  17  13  723            0.7763  \n",
       "Robust covariance outliers 1x  14   5  731            0.7767  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Recall performance of the Robust Covariance with contamination factor being 4x the outliers fraction has slightly better Recall than the one with 2x\n",
    "Overall, Robust Covariance is significantly better than OCSVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Average_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM RBF</th>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>0.6276</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>676</td>\n",
       "      <td>0.4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM poly degree 2</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>667</td>\n",
       "      <td>0.2202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novelty OCSVM poly degree 3</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>667</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 4x</th>\n",
       "      <td>0.9338</td>\n",
       "      <td>0.6336</td>\n",
       "      <td>0.9404</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>687</td>\n",
       "      <td>0.7766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 2x</th>\n",
       "      <td>0.9801</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>0.986</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>723</td>\n",
       "      <td>0.7763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robust covariance outliers 1x</th>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>731</td>\n",
       "      <td>0.7767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Accuracy Precision  Recall      F1 ROC AUC  FN  \\\n",
       "Novelty OCSVM RBF               0.9139    0.5909  0.8277  0.6276  0.9489   5   \n",
       "Novelty OCSVM poly degree 2      0.894    0.5438  0.6637   0.555  0.7966  11   \n",
       "Novelty OCSVM poly degree 3      0.894    0.5438  0.6637   0.555  0.7953  11   \n",
       "Robust covariance outliers 4x   0.9338    0.6336  0.9404  0.6917  0.9859   1   \n",
       "Robust covariance outliers 2x   0.9801     0.782  0.9385  0.8418   0.986   2   \n",
       "Robust covariance outliers 1x   0.9868     0.865   0.865   0.865  0.9861   5   \n",
       "\n",
       "                               TP  FP   TN Average_Precision  \n",
       "Novelty OCSVM RBF              14  60  676            0.4337  \n",
       "Novelty OCSVM poly degree 2     8  69  667            0.2202  \n",
       "Novelty OCSVM poly degree 3     8  69  667            0.2244  \n",
       "Robust covariance outliers 4x  18  49  687            0.7766  \n",
       "Robust covariance outliers 2x  17  13  723            0.7763  \n",
       "Robust covariance outliers 1x  14   5  731            0.7767  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do an outer join of the new metrics_df with the existing 0nes from before \n",
    "cumulative_metrics_df = pd.concat([cumulative_metrics_df, metrics_df], axis = 0) \n",
    "cumulative_metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 3 Ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 4 Begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='633'>Using Isolation Forest for Novelty Detection </a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
